[pytest]
#
# Comprehensive logging is always enabled for this tool.
#
# To analyse and troubleshoot between rounds:
#   - Review logs/harness_run.log for a persistent overview and debugging information for the entire run.
#   - Review logs/iteration_XXX.log for detailed, step-by-step logs of each individual iteration.
#
# Use these logs to trace execution, identify issues, and compare outcomes between rounds.
#
markers =
    bootstrap: Tests for basic harness setup and external tool accessibility
    loop: Tests for the core execution loop mechanics
    llm: Tests for the local LLM evaluation logic
    persistence: Tests for logging and state management
    convergence: Tests for loop termination conditions
    mesh: Tests for multi-agent collaboration (optional)
    ledger: Tests for the Ledger class and state persistence
    vesper: Tests for the VesperMind council evaluation logic
    council_planning: Tests for the council planning enforcement logic
    ui: Tests related to the UI server and frontend interaction
    control: Tests for interrupt handling and dynamic goal reloading
    resilience: Tests for system resilience and recovery capabilities
    long: marks tests as long-running (skipped by default)

addopts = -m "not long"
